# 操作系统复习习题

## Introduction

**1** What is the main advantage of multiprogramming?

> :one: 资源利用率高，多个作业共享CPU、内存、外设等资源
>
> :two: 系统吞吐量大

**2** Define the essential properties of the following types of operating systems:

   a. Batch      b. Time sharing

   c. Real time   d. Network

   e. Distributed

> :one: batch：即批处理，指的是具有相似需求的作业被成批排在一起，由操作员或自动作业定序器成组地在计算机上运行，使用于很少交互的大型任务
>
> :two: time sharing：即分时，指的是多个用户共享使用同一台计算机，多个程序分时共享硬件和软件资源
>
> :three: real time: 即实时，即操作系统在外界事件或数据产生时，能够接受并以足够快的速度予以处理，并作出快速响应，具有严格的时间限制
>
> :four: network：即网络，指的是在一般操作系统功能的基础上提供网络通信和网络服务功能
>
> :five: distributed：即分布式，指的是系统将计算分配到若干个物理处理机上，处理器不共享内存或时钟，每个处理器有自己的本地存储器，通过各种通信设施如高速总线、电话线等进行处理器之间的通信。

3 下面哪些指令是特权指令？

  A．设置定时器的值  B. 读时钟

  C. 清除内存    D 关闭中断

  E．从用户模式切换到监督模式

>  A\C\D属于特权指令

4 、分时系统追求的目标是：**快速响应用户**

5、批处理系统的主要缺点是：**无交互能力**

6、现代操作系统中最基本的两个特征是：**并发和共享**



## OS structures

**1** What is the purpose of system calls?

> 系统调用的目的是为操作系统提供服务接口

**2** What is the main advantage of the layered approach to system design?

> 层次化系统设计的好处：①低层和高层分别实现，便于系统进行扩展②高层错误不会影响到低层，便于调试，利于功能的增删改③调用关系清晰，高层对低层单向依赖，避免递归调用，有利于保证设计和实现的正确性

**3** What is the main advantage of the microkernel approach to system design?

> 微内核系统设计的好处：①易于扩展，易于移值 ②提高系统的可靠性 ③提供多种操作环境 ④便于实现分布计算

4 ‏在中断发生后，进入中断处理的程序属于：**操作系统程序**



## 进程

**1、 Describe the differences among short-term, medium-term, and long-term scheduling.**

> 短程调度从准备执行的进程（就绪队列）中选择进程并分配CPU，切换频率高
>
> 中程调度可将进程从内存（或从CPU竞争）中移出，从而降低多道程序程度，之后可被重新调入内存并从中断处执行，即进行进程交换
>
> 长程调度从磁盘上的缓冲池中选择进程并将其加载到内存中执行，进程进入就绪队列，速度较慢



**2、 Describe the actions taken by a kernel to context-switch between processes.**

> 当发生上下文切换时，内核CPU会将旧进程的上下文保存在PCB中并加载计划进行的新进程的上下文。



**3、采用下述程序，确定A、B、C、D四行中pid和pid1的值。（假设父进程和子进程的pid分别为2600和2603）**

```c
#include
#include
#include 
int main()
{
 pid_t pid,pid1;
 pid=fork();
 if (pid<0)
 {
  fprintf(stderr,"fork fail");
  return 1;
 }
 else if (pid==0)//在子进程中
 {
   pid1=getpid();
   printf("child:pid=%d",pid);   //A
   printf("child:pid1=%d",pid1);   //B
  }
  else//在父进程中
  {
   pid1=getpid();//获取当前进程id
   printf("parent:pid=%d",pid);   //C
   printf("parent:pid1=%d",pid1);  //D
   wait(NULL);
  }
 return 0;
}
```

> A: pid=0 	B: pid1=2603
>
> C: pid=2603 	D: pid1=2600

## 线程

**1.**   **Discuss the difference between user-level thread and kernel level thread.**

> :one: 调度方式上：内核级线程的调度和切换于进程的调度和切换非常相似，用户级线程不需要操作系统的支持
>
> :two: 调度单位上：用户线程的调度以进程为单位进行，在采用时间片轮转调度算法时，每个进程分配相同的时间片；对于内核级线程，每个线程分配时间片

**2.**   **Which of the following components of program state are shared across threads in a multithreaded process?**

**a. Register values**

**b. Heap memory**

**c. Global variables**

**d. Stack memory**

>  多线程进程中的线程共享堆内存和全局变量，不共享寄存器和栈

**3.**   **The program shown below uses the Pthreads API. What would be output from the program at LINE C and LINE P?**

```c
#include
#include
int value=0;
void *runner(void *param); /* the thread */
int main()
{
  int pid;
  pthread_t tid;
  pthread_attr_t attr;
  pid=fork();
  if(pid==0)
  {
   pthread_attr_init(&attr);
   pthread_create(&tid, &attr, runner, NULL);
   pthread_join(tid, NULL);
   printf("CHILD: value=%d\n", value); /* LINE C */
  }else if(pid>0){
   wait(NULL);
   printf("PARENT: value=%d\n",value);　/* LINE P */
  }
}
void *runner(void *param)
{
  value=5;
  pthread_exit(0);
}
```

```c
value为全局变量，父进程会等待子进程完成再打印，子进程在线程完成后打印value，

子进程会复制父进程的堆、栈、数据段等信息，两者是独立的（在子进程修改全局变量不会影响父进程中的同名全局变量），而进程中的线程会与该进程共享数据段（里面包括全局变量）和堆内存。

所以LINE C打印value值5       LINE P 打印value值0
```

**4、请说明三种多线程模型及其优缺点。** 

> :one: 多对一模型：多个用户级线程映射到单个内核级线程，用于不支持内核线程的系统中
>
> 缺点：任意时刻只有一个线程可以访问内核，并发度较低，一个用户线程发起系统调用而阻塞则整个进程阻塞
>
> :two: 一对一模型：一个用户级线程映射到一个内核级线程
>
> 优点：提供了更好的并发性，一个用户级线程阻塞允许另一个线程运行
>
> 缺点：每创建一个用户级线程就需要创建一个内核线程，带来了额外的开销
>
> :three: 多对多模型：多个用户级线程映射到多个内核级线程
>
> 优点：不限制应用的线程数，多个线程可实现真正的并发

## 调度

**1** **Why is it important for the scheduler to distinguish I/O-bound programs from CPU-bound programs?**

>  I/O限制程序和CPU限制程序操作对CPU的使用有较大的差别，I/O限制程序只需要少量的CPU时间片，大部分时间用于I/O的等待，而CPU操作需要用整块时间，在CPU操作的后台可以同时运行I/O等待操作，二者互不影响，区分两种操作，加上系统的调用，可以更好的利用CPU资源，提高运行效率。

**2** **Consider the following set of processes, with the length of the CPU burst given in milliseconds:**       

| **Process** | **Burst Time** | **Priority** |
| ----------- | -------------- | ------------ |
| **P1**      | **10**         | **3**        |
| **P2**      | **1**          | **1**        |
| **P3**      | **2**          | **3**        |
| **P4**      | **1**          | **4**        |
| **P5**      | **5**          | **2**        |

**The processes are assumed to have arrived in the order P1, P2, P3, P4, P5, all at time 0.**

  **a. Draw four Gantt charts that illustrate the execution of these processes using the following scheduling algorithms: FCFS, SJF, nonpreemptive priority (a smaller priority number implies a higher priority), and RR (quantum = 1).**

  **b. What is the turnaround time of each process for each of the scheduling algorithms in part a?**

  **c. What is the waiting time of each process for each of the scheduling algorithms in part a?**

  **d. Which of the algorithms in part a results in the minimum average waiting time (over all processes)?**

> a) ![image-20211221204519516](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211221204519516.png)
>
> b）各进程的周转时间
>
> |      | FCFS | SJF  | 非抢占式优先级 | RR   |
> | ---- | ---- | ---- | -------------- | ---- |
> | P1   | 10   | 19   | 16             | 19   |
> | P2   | 11   | 1    | 1              | 2    |
> | P3   | 13   | 4    | 18             | 7    |
> | P4   | 14   | 2    | 19             | 4    |
> | P5   | 19   | 9    | 6              | 14   |
> | AVG  | 13.4 | 7    | 12             | 9.2  |
>
> c）各进程等待时间
>
> |      | FCFS | SJF  | 非抢占式优先级 | RR   |
> | ---- | ---- | ---- | -------------- | ---- |
> | P1   | 0    | 9    | 6              | 9    |
> | P2   | 10   | 0    | 0              | 2    |
> | P3   | 11   | 2    | 16             | 5    |
> | P4   | 13   | 1    | 18             | 3    |
> | P5   | 14   | 4    | 1              | 9    |
> | AVG  | 9.6  | 3.2  | 8.2            | 5.6  |
>
> d）最小平均等待时间为SJF:  3.2

**3** **Which of the following scheduling algorithms could result in starvation?**

   **a. First-come, first-served**

   **b. Shortest job first**

   **c. Round robin**

   **d. Priority**

>  答：SJF和优先级调度算法会引起饥饿

**4** **The traditional UNIX scheduler enforces an inverse relationship between priority numbers and priorities: The higher the number, the lower the priority. The scheduler recalculates process priorities once per second using the following function:**

**Priority = (Recent CPU usage / 2) + Base**

**where base = 60 and recent CPU usage refers to a value indicating how often a process has used the CPU since priorities were last recalculated. Assume that recent CPU usage for process P1 is 40, process P2 is 18, and process P3 is 10. What will be the new priorities for these three processes when priorities are recalculated? Based on this information, does the traditional UNIX scheduler raise or lower the relative priority of a CPU-bound process?**

>  优先级： P1:40/2+60=80	P2:18/2+60=69	P3:10/2+60=65
>
>  降低了相对优先级

**5、SJF调度算法的平均等待和平均周转时间最短。**

**6、降低进程优先级的合理时机是<mark>进程时间片用完</mark>**

**7、<mark>先来先服务调度算法</mark>有利于CPU繁忙型的作业，而不利于I/O繁忙型的作业。**

## 调度

对信号量S执行P操作后，使进程进入等待队列的条件是<mark>S.value<0</mark>。

‏在操作系统中，要对并发进程进行同步的原因是<mark>并发进程是异步的。</mark>

临界区就是临界资源所在的区域: 错误：<mark>临界区是访问临界资源的那段代码。</mark>

信号量是一个整型变量，可以直接对其进行加1和减1的操作:错误：<mark>对信号量只能执行初始化以及PV操作。P操作内部能执行减1</mark>操作。

一个正在访问临界资源的进程因为申请I/O操作而阻塞时，它允许其他进程进入其临界区:错误:<mark>临界区要互斥访问</mark>

## 死锁

**Consider the traffic deadlock depicted in Figure 7.10.**

**a. Show that the four necessary conditons for deadlock indeed hold in this example.**

 **b. State a simple rule for avoiding deadlocks in this system.**

<img src="https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211101193926522.png" alt="image-20211101193926522" style="zoom:67%;" />

**解答**

> a) 如图所示例子满足死锁发生的四个必要条件
>
> 1. **互斥**：每个路口一次只能通过一辆汽车。
> 2. **占有并等待**：处在路口的车占有这个路口，并且等待其它车前进。
> 3. **不可抢占**：每一辆车都不能去抢占其它车的位置。
> 4. **循环等待**：每一辆车都在等待其他车辆前进，你等待我，我等待你，形成一个环。
>
> b) 避免该系统发生死锁的规则如下：
>
> ​	不允许车辆在十字路口停留，如果无法进入下一个街道，则在当前街道停留。
>



**Consider the following snapshot of a system:**

![image-20211101195139380](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211101195139380.png)

Answer the following questions using the banker’s algorithm:

  a. What is the content of the matrix Need?

  b. Is the system in a safe state?

  c. If a request from process P1 arrives for (0,4,2,0), can the request be granted immediately?

**解答**

a) Need = Max - Allocation   

 Need矩阵可得

![image-20211101200959489](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211101200959489.png)

b) 判断当前系统状态是否安全如下：

![image-20211101202017342](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211101202017342.png)

经过安全算法运算可知，存在安全序列<P0,P2,P3,P4,P1>

所以当前系统处于安全状态

c) 对于P1的请求Request1（0，4，2，0）<=Available（1，5，2，0）而且Request1（0，4，2，0）<=Need1（0，7，5，0）

假定该请求会被满足，会产生如下新状态：

![image-20211101203758152](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211101203758152.png)

![image-20211101204938954](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211101204938960.png)

1、经过安全算法运算可知，存在安全序列<P0,P2,P3,P4,P1>,所以可以马上同意P1的请求

2、死锁的避免是根据（<mark>**防止系统进入不安全状态**</mark> ）采取措施实现的

3、某系统中有三个并发进程都需要四个同类资源，该系统不会发生死锁的最少资源是（ 10个）。

> 每个进程都得到三个资源，最后一个留给先运行的进程然后再释放。

4、在一个有N个进程的单处理机系统中，有可能出现N个进程都被阻塞的情况：正确:+1:

## 内存管理

**8.1** **Explain the difference between internal and external fragmentation.**

 解：

> 内碎片：一个分区进程占用后剩下的多余部分，存在于分区的内部
>
> 外碎片：无法被任何一个进程占用的小分区



**8.3** **Given five memory partitions of 100 KB, 500 KB, 200 KB, 300 KB, and 600 KB (in order), how would each of the first-fit, best-fit, and worst-fit algorithms place processes of 212 KB, 417 KB, 112 KB, and 426 KB (in order)? Which algorithm maKes the most efficient use of memory?**

解：

:one: 首次适应算法first-fit

> 212KB分配空间：找到第二个空闲分区500KB>212KB，剩余288KB空闲分区
>
> 417KB分配空间：找到第五个空闲分区600KB>417KB，剩余183KB空闲分区
>
> 112KB分配空间：找到第二个空闲分区288KB>112KB，剩余176KB空闲分区
>
> 426KB分配空间：需要等待

:two: 最佳适应算法best-fit

> 将内存分区按照从小到大排序：100KB、200KB、300KB、500KB、600KB
>
> 212KB分配空间：找到第三个空闲分区300KB>212KB，剩余88KB空闲分区
>
> 417KB分配空间：找到第四个空闲分区500KB>417KB，剩余83KB空闲分区
>
> 112KB分配空间：找到第二个空闲分区200KB>112KB，剩余88KB空闲分区
>
> 426KB分配空间：找到第五个空闲分区600KB>426KB，剩余174KB空闲分区

:three: 最差适应算法worst-fit

> 将内存分区按照从小到大排序：600KB、500KB、300KB、200KB、100KB
>
> 212KB分配空间：找到第一个空闲分区600KB>212KB，剩余388KB空闲分区
>
> 417KB分配空间：找到第二个空闲分区500KB>417KB，剩余83KB空闲分区
>
> 112KB分配空间：找到第一个空闲分区388KB>112KB，剩余276KB空闲分区
>
> 426KB分配空间：需要等待

:four: 综上，best-fit是最有效率的算法



**8.9. Consider a paging system with the page table stored in memory.**

**a. If a memory reference takes 200 nanoseconds(200纳秒), how long does a paged memory reference take?**

**b. If we add TLBs, and 75 percent of all page-table reference are found in the TLBs, what is the effective memory reference time?(Assume that finding a page-table entry in the TLBs taKes zero time, if the entry is there)**

解：

> :one: 每一次的数据/指令存取需要两次内存存取，一次是存取页表，一次是存取数据,所以一次分页内存引用需要时间为：$200ns\times 2=400ns$
>
> :two: 如果引入TLBs，有效内存引用时间为：$200ns\times 2 \times 25\%+200ns\times 75 \%=250ns$



**8.12** **Consider the following segment table:**

| **Segment** | **Base** | **Length** |
| ----------- | -------- | ---------- |
| **0**       | **219**  | **600**    |
| **1**       | **2300** | **14**     |
| **2**       | **90**   | **100**    |
| **3**       | **1327** | **580**    |
| **4**       | **1952** | **96**     |

   **What are the physical addresses for the following logical addresses?**

​    **a. 0,430**

​    **b. 1,10**

​    **c. 2,500**

​    **d. 3,400**

​    **e. 4,112**

解：

> **a**：430<600，没有越界，物理地址：219+430=649
>
> **b**：10<14，没有越界，物理地址：2300+10=2310
>
> **c**：500>100，越界了
>
> **d**：400<580，没有越界，物理地址：1327+400=1727
>
> **e**：112>96，越界了



![image-20211222164740416](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211222164740416.png)

![image-20211222170600380](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211222170600380.png)



不会产生内存碎片的存储管理是（ **分页式存储管理**）

分区管理中采用“最佳适应”分配算法时，把空闲区按（ **长度递增**）次序登记在空闲区表中。

对重定位存储管理方式，应（**在整个系统中设置一个重定位寄存器**）

## 虚拟内存

**9.4 A certain computer provides its users with a virtual-memory space of $2^{32}$ bytes. The computer has $2^{18}$ bytes of physical memory. The virtual memory is implemented by paging, and the page size is 4,096 bytes. A user process generates the virtual address 11123456. Explain how the system establishes the corresponding physical location. Distinguish between software and hardware operations.**

> **中文描述**：某台计算机为其用户提供了一个$2^{32}$ 字节的虚拟内存空间。该计算机有$2^{18}$ 字节的物理内存。虚拟内存是通过分页实现的，分页大小为4,096字节。一个用户进程产生了虚拟地址11123456。解释一下系统如何建立相应的物理位置。区分软件和硬件的操作。

>  **解：**
>
>  :one: 虚拟地址转换为二进制表示：0001 0001 0001 0010 0011 0100 0101 0110	
>
>  :two: 分页大小为4096=$2^{12}$，所以页表大小为$2^{20}$,低阶的12位0100 0101 0110被用作进入页面的位移，而剩下的20位0001 0001 0001 0010 0011被用作页号
>
>  :three: 由于该计算机物理内存为$2^{18}$ 字节，所以主存共有64块
>
>  :four: 建立物理位置的过程: 查询页表中页号为0001 0001 0001 0010 0011所对应的块号，物理地址即为对应的物理块号的起始地址+页面偏移0100 0101 0110



**9.10 Consider a demand-paging system with the following time-measured utilizations:**

| **CPU utilization**   | **20%**   |
| --------------------- | --------- |
| **Paging disk**       | **97.7%** |
| **Other I/O devices** | **5%**    |

  **For each of the following, say whether it will (or is likely to) improve CPU utilization. Explain your answers.**

**a.  Install a faster CPU.**

**b.  Install a bigger paging disk.**

**c.   Increase the degree of multiprogramming.**

**d.  Decrease the degree of multiprogramming.**

**e.  Install more main memory.**

**f.   Install a faster hard dist or multiple controllers with mutiple hard disks.**

**g.  Add prepaging to the page-fetch algorithms.**

**h.  Increase the page size.**

> **中文描述**：假定有一个请求分页存储管理系统，测得系统各相关设备的利用率为：CPU利用率为20%，磁盘交换区为99.7%：其他I/O设备为5%。下面哪些措施将可能改进CPU的利用率，解释你的回答
> a．安装更快的CPU	b. 安装更大的分页磁盘	c. 提高多道程度	d. 降低多道程度	e. 安装更多的内存
>
> f. 安装更快的硬盘或者具有多个硬盘的多个控制器	g. 为页面获取算法添加预先调页	h. 增加页面大小

>  **解：**
>
>  **a、b、c**：无法提升CPU的利用率
>
>  **d**: 降低多道程序可以提高CPU利用率，因为这个系统会在分页上花费大量时间，而减小多道程度可以降低分页错误的频率，从而有效提高CPU利用率
>
>  **e**: 安装更多的内存可以提高CPU利用率，因为更大的内存意味着内存中可以存储更多的页，发生与硬盘页置换的概率就越低，从而CPU可以提高利用率
>
>  **f**: 安装更快的硬盘或者具有多个硬盘的多个控制器可以提高CPU利用率，因为这可以提高与硬盘交换数据的速度，CPU获取数据的速度自然也越快。
>
>  **g**: 为页面获取算法添加预先调页可以让CPU获得数据的速度更快，从而可以提高CPU利用率
>
>  **h**:  增加页面大小可以减少在频繁的数据访问过程中的页面错误，从而提高CPU利用率

页式虚拟存储管理的主要特点是（**不要求将作业同时全部装入到主存的连续区域**)

当系统发生抖动（ Thrashing）时，可用采取的有效措施是:**撤销部分进程**

考虑页面置換算法，系统有m个物理块供调度，初始时全空，页面引用串长度为p，包含了n个不同的页号，无论用什么算法，缺页次数不会少于（ n）。

> 无论采用哪种页面置换算法，每个页第一次被访问时都会缺页，所以缺页次数至少是n

## 文件系统

**10.1** **Consider a file system where a file can be deleted and its disk space reclaimed while links to that file still exist. What problems may occur if a new file is created in the same storage area or with the same absolute path name? How can these problems be avoided?**

> 答：
>
> 如果新创建的文件处在同一存储区域或具有相同的绝对路径名称，将会出现**如下问题**：假设文件1是已经被删除的文件，文件2是新创建的文件，则通过现有链接访问文件1的用户将会访问文件2，用户无法访问到想要访问的文件1
>
> **解决办法**：
>
> > :one: 维护一个文件的所有链接列表，在删除文件时删除其中的每个链接
> >
> > :two: 保留链接，当试图访问已删除文件时删除它们
> >
> > :three: 维护一个**文件引用列表(或计数器)**，仅在删除所有指向该文件的链接或引用之后才删除该文件。

 

**11.1** **Consider a file system that uses a modified contiguous-allocation scheme with support for extents. A file is a collection of extents, with each extent corresponding to a contiguous set of blocks. A key issue in such system is the degree of variability in the size of the extents. What are the advantages and disadvantages of the following schemes?**

​    **a. All extents are of the same size, and the size is predetermined.**
​	**b. Extents can be of any size and are allocated dynamically.**
​	**c. Extents can be of a few fixed sizes, and these sizes are predetermined.**

>  **答：**
>
>  :one: 如果所有扩展都是同样大的，并且预先定义了，优点则是快分配简单，利用一个位图或空闲表则可解决，缺点是不够灵活
>
>  :two: 如果扩展可以是任意大小的，并且可以动态分配，优点则是灵活性高，缺点显然为分配块的复杂性高，可能会产生外碎片
>
>  :three: 如果扩展时一些预先定义的、固定大小的，则需要为每一个可能大下的扩展维护一个单独的位图或空闲表，此时的复杂度和灵活性位于:one:和:two:之间



**11.2** **What are the advantages of the variant of linked allocation that uses a FAT to chain together the blocks of a file?**

>  **答：**
>
>  连接分配的一个变种采用FAT来链接所有文件的块，优点是，在访问存储在文件中间的块时，能通过追寻存储在FAT中的指针来确定位置，而不是以顺序的方式访问文件的所有单个块来找到目标块的指针。通常情况下，大部分的FAT可以被缓存在内存中，因此可以只通过内存访问来确定指针，而不必访问磁盘块，速度也会快很多。



11.3 Consider a system where free space is kept in a free-space list.

​    a. Consider a file system similar to the one used by UNIX with indexed allocation. How many disk I/O operations might be required to read the contents of a small local file at /a/b/c? Assume that none of the disk blocks is currently being cached.

​    b. Suggest a scheme to ensure that the pointer to the free space list is never lost as a result of memory failure.

>  **答：**
>
>  :one: 读取本地小文件/a/b/c的内容涉及4个独立的磁盘操作:读取包含根目录/的磁盘块，读取包含目录b的磁盘块，读取包含目录c的磁盘块读取、包含文件c的磁盘块
>
>  :two: 解决办法：可以将空闲空间列表的指针存储在硬盘中

**12.2** **Suppose that a disk drive has 5,000 cylinders, numbered 0 to 4999. The drive is currently serving a request at cylinder 143, and the previous request was at cylinder 125. The queue of pending requests, in FIFO order, is:**

​     **86,1470,913,1774,948,1509,1022,1750,130**

  **Starting from the current head position, what is the total distance (in cylinders) that the disk arm moves to satisfy all the pending requests for each of the following disk-scheduling algorithms?**

**a.**   **FCFS**

![image-20211125112235150](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211125112235150.png)

磁盘臂走过的总距离为：$(143-86+1470-86+1470-913+1774-913+1774-948+1509-948+1509-1022+1750-1022+1750-143)=7068\ cylinders$

**b.**   **SSTF**

![image-20211125113213959](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211125113213959.png)

磁盘臂走过的总距离为：$(143-86+1774-86)=1745\ cylinders$

**c.**    **SCAN**

![image-20211125113607276](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211125113607276.png)

磁盘臂走过的总距离为：$(143-0+1774-0)=1913\ cylinders$

**d.**   **LOOK**

![image-20211125114454530](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211125114454530.png)

磁盘臂走过的总距离为：$(143-86+1774-86)=1745\ cylinders$

**e.**   **C-SCAN**

![image-20211125114231155](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211125114231155.png)

磁盘臂走过的总距离为：$(143-0+4999-0+4999-913)=9228\ cylinders$

**f.**    **C-LOOK**

![image-20211125114806527](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211125114806527.png)

磁盘臂走过的总距离为：$(143-86+1774-86+1774-913)=2606\ cylinders$



假设磁盘的每个磁道分成9个块，现有一文件有A，B，C，……I共9个记录，每个记录的大小与块的大小相等，设磁盘的转速为27ms/r，每读出一块后需要2ms的处理时间，若忽略其他时间，试问：

1）如果顺序存放这些记录，顺序读取，处理该文件要多少时间？

2）如果要顺序读取这些文件，记录如何存放处理时间最短？

![image-20211222232244462](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img13/image-20211222232244462.png)

## I/O系统

1、**什么是设备独立性？ 为什么要引入设备独立性？如何实现设备独立性？**

> **答**：
> :one: 含义：设备独立性是指应用程序独立于具体使用的物理设备
>
> :two: 目的: 为了提高OS的可适应性和可扩展性
>
> :three: 如何实现: 
>
> > 应用程序使用逻辑设备名称来请求使用设备
> >
> > 系统使用物理设备名
> >
> > 系统需将逻辑设备名称转换为某物理设备。 

2、简述**SPOOLing**技术。

> **答**：
>
> :one: 利用多道程序中的一道程序来模拟脱机输入时的外围控制机的功能，把低速I/O设备上的数据传送到高速磁盘上；用另一道程序来模拟脱机输出时外围控制机的功能，把数据从磁盘传送到低速输出设备上这样，便在主机的直接控制下，实现脱机输入、输出功能。此时的外围操作与CPU对数据的处理同时进行，这种在联机情况下实现的同时外围操作称为**SPOOLing** (Simultaneous Peripheral Operations On-Line)，或称假脱机操作。
>
> :two: SPOOLing系统是对脱机输入、输出工作的模拟，它必须有高速随机外存的支持，这通常是采用磁盘。
>
> :three: SPOOLing系统组成包括：输入井和输出井；输入缓冲和输出缓冲；输入进程和输出进程。
>
> :four: SPOOLing系统的特点为: 提高了I/O速度、将独占设备改造为共享设备、实现了虚拟设备功能

3、**设备驱动程序要完成哪些工作**？

> **答**:
>
> :one: 将抽象要求转化为具体要求
>
> :two: 检查I/O请求的合法性
>
> :three: 读出和检查设备的状态
>
> :four: 传送必要的参数
>
> :five:工作方式的设置
>
> :six: 启动I/O设备

4、n某文件占10个磁盘块，现要把该文件磁盘块逐个读入内存，并送用户区进行分析，假设一个缓冲区与一个磁盘块大小相同，把一个磁盘块读入缓冲区的时间为100us，将缓冲区的数据传送到用户区的时间是50us，CPU对一块数据进行分析的时间是50us。在单缓冲和双缓冲区结构下，读入并分析完该文件的时间分别是多少？

> 答：
>
> 在单缓冲的情况下，当上一个磁盘块从缓冲区读入用户去时下一个磁盘块才能开始读入，将读入缓冲区和传送用户区作为一个单元，共有十个这样的单元，也就是$10\times 150us=1500us$，加上最后一个块的CPU处理时间$50us$，一共是1550us
>
> 在双缓冲情况下，读入第一个缓冲区以后立即开始读入第二个缓冲区，读完第二个缓冲区以后，第一个缓冲区的数据已经送到了用户区，所以不用等待磁盘块从缓冲区读入用户区，只用算最后一个块的运送到用户区并CPU处理的时间：$10\times100+50+50=1100us$

  假设一个含有100个磁盘块的文件，且文件控制块已经在内存中，那么采用连续分配、链接分配和索引分配时，执行下述操作分别要做多少次I/O 操作？

  1.在开头加入一块

  2.在中间加入一块

3. 在末端加入一块

4. 在末端删除一块

> 磁盘块离开原有位置进行一次I/O操作，进入新的位置又进行一次，写入新增块需要启动一次磁盘；将修改后的PCB存盘需要一次I/O
