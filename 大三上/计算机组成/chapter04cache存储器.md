# 第四章 cache存储器（重点）

## key points

> **1、存储器系统的特性有哪些，其中一个重要的就是数据的存取方式，各是什么，对应哪些存储器，速度如何？**
>
> **2、存储器的功能有哪些？如何衡量存储器的性能？三方面**
>
> **3、存储器的分层结构，为什么要引入分层结构，目前常用的分层结构是什么样的，引入存储器分层结构的依据是什么？局部性原理**
>
> **4、局部性原理：时间局部性与空间局部性**
>
> <mark>**5、Cache是重头戏，可以出大题**</mark>
>
> **6、Cache的概念、目的、对于程序员是否透明、写入方式是什么？Cache行和块的关系，怎么对应，典型的Cache组织**
>
> **7、Cache的设计要素有哪些，容量、映射功能、替换算法、写策略、行大小、Cache数目，每一个都是重点，其中映射功能和替换算法最重要**
>
> <font color="red">**8、映射功能：直接映射、关联映射和组关联映射**</font>
>
> **9、Cache数目，多级Cache的级数以及统一和分立Cache各自的特点，目前流行的多级Cache是如何组织的**

计算机的存储器被组织成层次结构，最顶层(最接近处理器)是处理器内的寄存器，接下来是一级或多级的高速缓存cache，再往下走是主存，通常由动态随机存取存储器DRAM构成，以上这些都是系统内部的存储器。存储层次继续划分外部存储器，下一层通常是固定硬盘，再往下走是可装卸的存储设备

## 4.1 计算机存储系统概述

### 4.1.1 存储系统的特性

存储系统最重要的一些特性如下：

![image-20211031201134319](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704116.png)

**字**:存储器组织的“自然”单元。字长通常与一个整数的数据位数和指令长度相等，但也有很多例外。

**可寻址单元**:在某些系统中，可寻址单元是字，但许多系统允许在字节级上寻址。在任何情况下，地址位长度A和可寻址的单元数N之间的关系为: 2^A=N。

**传输单元**:对于主存储器，这是指每次读出或写人存储器的位数。传输单元不必等于一个字或一个可寻址单元。对于外部存储器，数据的传送经常是以比一个字大得多的单元来传送，这就是所谓的**块**。

从用户的观点来看，存储器两种最重要的特性是**容量和性能(performance)**,通常需要3种性能参数:

**存取时间(延迟)**:对于随机存取存储器，这是执行一次读或写操作的时间，即从地址传输给存储器的时刻到数据已经被存储或使用为止所花的时间。而对于非随机存取存储存取时间是把读写结构定位到所需要的存储位置所花费的时间。

**存储周期时间**:这个概念主要用于随机存取存储器，它是存取时间加上下一次存取之前所需要的附加时间。这里附加时间用于瞬变的信号消失或数据破坏性读后的再生。需要注意，**存储周期时间是与系统总线有关，而不是与处理器相关。**

**传输率**:这是数据传人或传出存储单元的速率。对于随机存取存储器，它等于“1/周期时间”。而对于<font color="red">非随机存取存储器，有下列关系</font>:
$$
T_N=T_A+\frac{n}{R}
$$
其中：$T_N$：读或写N位的平均时间

​			$T_A$：平均读取时间

​			$n$：位数

​			$R$：传输率，单位是b/s（位/秒）

#### 存储器的存取方式

存取方式包括以下四类

**sequential顺序存取**

> 从头开始，按顺序通读
>
> 访问时间取决于数据的位置和之前的位置
>
> 例如磁带
>

**direct直接存取**

> 每个块有唯一的地址
>
> 访问是通过跳转到附近加上顺序搜索
>
> 访问时间取决于位置和之前的位置
>
> 例如磁盘，光盘

**random随机存取**

> 通过每一个地址准确地识别位置
>
> 访问时间与位置或之前的访问无关
>
> 如DRAM
>

**associative关联存取**

> **是一种随机存取**
>
> 数据是通过与地址中所有**字的部分内容**进行比较来定位的
>
> 访问时间与位置或之前的访问无关
>
> 例如缓存

### 4.1.2 存储器层次结构

存取时间越短，平均每位的花费就越大；存储容量越大，平均每位的花费就越小；存储容量越大，存取时间就越长。

![image-20211225135123451](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704117.png)

对于以上的层次结构，随着层次的下降：每位价格下降、容量增大、存取时间变长、处理器访问存储器的频率降低

## 4.2 Cache存储器原理

cache存储器的目的是使存储器的速度逼近可用的最快存储器的速度，同时以较便宜的半导体存储器的价格提供一个大的存储器容量。

cache中存放了主存储器的部分副本。当CPU试图访问主存中的某个字时，首先检查这个字是否在cache 中，如果是，则把这个字传送给CPU;如果不是，则将**主存中包含这个字固定大小的块**读人cache中，然后再传送该字给CPU。

因为访问的局部性，当把某块数据存人cache,以满足某次存储器的访问时，CPU将来还很有可能访问同一存储位置或该数据块中的其他字。
<img src="https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704128.png" alt="image-20211031203640712" style="zoom:67%;" />

主存储器有多达$2^n$个可寻址的字组成，每一个字都有唯一的n位地址，我们将主存看成许多定长的块，每个块有K个字，块数为$M=2^n/K$.

而cache包含m个块，**称为行**，每行包括K个字和几位标记以及控制位。行的长度，不含标记和控制位，称为行大小。

行的数量远远小于主存的块的数目。由于块数多于行数，所以单个行不可能永远的被某个块专用，因此需要一个标记位tag，这个通常是主存储器地址的一部分。

![image-20211031204359380](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704119.png)

cache读操作

<img src="https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704129.png" alt="image-20211031204815738" style="zoom:67%;" />



## 4.3 Cache设计

cache设计的主要要素如下：

Size、Mapping Function Replacement Algorithm 、Write Policy 、Block Size 

Number of Caches、address of Cache

![image-20211008101540485](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704120.png)

### 4.3.2 cache 容量的选择

若选择小内存：便宜但是命中率低

若选择大内存：命中率高：整个存储系统的平均存取时间接近单个cache的存取时间；但是花费高；门电路多，会引起速度的降低；而且会占用更多的cpu空间

要做好权衡，没有最好的选择，1k~512k比较高效率

### 4.3.3 映射功能(考点)

映射机制是用硬件实现的

有三种典型的映射机制：直接映射direct mapping、全关联映射associative mapping、组关联映射set associative mapping

对于所有这三种映射方法，该例子中都包含下列条件:

> cache 能存储64KB。
>
> 数据在主存和cache之间以每块4字节大小传输。这意味着cache被组织$16K =2^{14}$行,每行4字节。
>
> 主存容量为16MB, 每个字节直接由24位的地址($2^24=16M$) 寻址。因此，为了实现映射，我们把主存看成是由4M个块组成，每块4字节。

### (1) 直接映射

主存中的块j和cache中的行i有如下直接映射关系：$i=j\ mode\ m$，其中m为cache的行数

<img src="https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704131.png" alt="image-20211031211207313"  />

**直接映射的实现**

存储器的地址会被分为三部分：

<img src="https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704132.png" alt="image-20211008104318843" style="zoom:80%;" />

低位是字内容；

中间的位标识cache的行，由cache初始的行数m所确定，$line=\log _2m$；

高位标识是哪一个块

tag域位数是用block域位数减去line域位数算出来的，不是直接分配

<img src="https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704133.png" alt="image-20211031210959717" style="zoom:67%;" />

<font color="red">**总结如下**</font>

> 地址长度=（s+w）位
>
> 可寻址的单元数=$2^{s+w}$个字或字节
>
> 块大小=行大小=$2^{w}$个字或字节
>
> 主存的块数=$2^{s}$
>
> cache的行数=m=$2^{r}$
>
> cache的容量=$2^{r+w}$个字或字节
>
> 标记长度tag=（s-r）位

**优点**：实现简单

**缺点**：较为固定、不够灵活

适用于大容量cache

### (2) 全关联映射

**全关联映射允许每一个主存块装入cache中的任意行，此时只需要用标记位表示一个主存块。**

![image-20211031212059064](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704122.png)

为了确认某一块是否在cache中，需要对每一行中的标记进行搜寻检查。**地址中无对应行号的字段**

<font color="red">**总结如下**</font>

> 地址长度=（s+w）位
>
> 可寻址的单元数=$2^{s+w}$个字或字节
>
> 块大小=行大小=$2^{w}$个字或字节
>
> 主存的块数=$2^{s}$
>
> cache的行数不由地址格式决定
>
> 标记长度tag=s位

**优点**：映射灵活，**命中率最高**

**缺点**：并行比较电路很难设计，系统开销大，用于比较小的cache

有空行放空行，没空行利用替换算法放

### (3) 组关联映射

现在的cache最经常采用的映射方法，前两种方法的折衷

**主存分成块、cache分成组**，在组关联映射中，cache分为v个组，每组包含k个行，它们的关系为：$m=v\times k$ 	$i=j\ mode\ v$

其中：i为cache组号、j为主存块号、m为cache的行数、v为组数、k为每组中的行数

这被称为k路组关联映射。采用组关联映射，块$B_0$能够映射到组j的任意行中。在全相联映射中，每一个字映射到多个cache行中。而对于组相联映射，每一个字映射到特定一组的所有cache 行中，于是，主存中的$B_0$块映射到第0组，如此等等。因此，组相联映射cache在物理上是使用了v个全关联映射的cache。同时，它也可看作为k个直接映射的cache的同时使用，如图4-13b所示。每一个直接映射的cache称为路，包括0个cache行。主存中首v个块分别映射到每路的v行中，接下来的v个块也是以同样的方式映射，后面也如此。直接映射一般应用于轻度关联(h 值较小)的情况，而全相联映射应用于高度关联的情况。

![image-20211013101411998](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704123.png)

![image-20211031212735041](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704124.png)

<font color="red">**总结如下**</font>

> 地址长度=（s+w）位
>
> 可寻址的单元数=$2^{s+w}$个字或字节
>
> 块大小=行大小=$2^{w}$个字或字节
>
> 主存的块数=$2^{s}$
>
> cache中每组的行数=k
>
> 组数=$2^d$
>
> cache行数=$m=kv=k\times 2^k$
>
> cache的容量=$k\times 2^k$个字或字节
>
> 标记长度=（s-d）位

**例题**

> 设某机内存容量为4MB,Cache的容量16KB,每块8个字,每个字32位.设计一个四路组相联映射(即Cache内每组包含4个字块)的Cache组织方式。
> 1)画出满足组相联映射的主存地址字段中各字段的位数
> 2)设Cache的初态为空,CPU从主存第0号单元开始连续访问100个字(主存一次读出一个字),重复此次序读8次,求存储访问的命中率
> 3)若Cache的速度是主存速度的6倍,求存储系统访问加速比

**解**

> 1）:one: 获得地址长度：地址长度=$\log_2(4MB/4B)=20bits$
>
> ​	  :two: 获得cache行数和组数：
>
> ​			字地址长度=$\log_2 8=3bits$
>
> ​			行数=$16KB/(8\times4B)=2^9$
>
> ​			对于四路组相联映射，每组有四行，所以组数地址长度=7bits
>
> ​			tag地址长度=20-7-3=1-bits
>
> ​	  :three: 画出地址表示图如下：
>
> ![image-20211031214826303](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704125.png)
>
> 2）首先要明确一点：<font color="red">只有在第一遍访问时才会存在未命中情况</font>，那么我们就需要计算第一次有多少个字没有命中。
> 当出现一次未命中时，主存就会把对应块上的数据传送到Cache中，那么我们只需要计算出第一遍遍历中主存向Cache传送了多少次数据，就可以得到未命中的次数.100个字需要100/8=13个块。那么第一遍便利的时候主存需要向Cache传送13次数据，也就是说有13次未命中。全部过程访问8x100=800次，未命中13次，则命中率为(800-13)/800=98.375%
>
> 3）设主存存取周期为6t，那Cache存取周期就为t。
> 加速比就为：6t/(98% xt+2% x7t)=5.3(times)



### 4.3.4 替换算法(考点)

基于速度的考虑，我们使用硬件来实现替换算法

**Least Recently used(LRU)**：最近最少使用的算法，替换掉那些在cache中最长时间未被访问的块。最经常使用。

> 对于两路组相联，这种方法很容易实现，每行包含一个USE位。当某行被引用时，其USE位被置为1,而这一组中另一行的USE位被置为0。当把块读入到这一组中时，就会替换掉USE位为0的行。由于我们假定越是最近使用的存储单元越有可能将被访问，因此，LRU会给出最佳的命中率。对于全相联cache, LRU也相对容易实现。高速缓存机制会为cache中的每行保留一个 单独的索引表。当某一行被访问时，它就会移动到表头，而在表尾的行将被替换掉

![image-20211013112446355](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704126.png)

**First in first out**：先进先出，替换掉在cache中停留时间最长的块

**Least frequently used**：最不经常使用

**Random**：性能与LRU几乎差不多

![image-20211031215824626](https://raw.githubusercontent.com/yijunquan-afk/img-bed-1/main/img2/1695704127.png)

### 4.3.5 写策略

与读不同，cache写更加复杂

当驻留在cache中的某块要被替换时，必须考虑两点。如果cache中的原块没有被修改过，那么它可以被直接替换掉，而不需要事先写回主存。如果在cache某行中至少在一个字上进行过写操作，那么在替换掉该块之前必须将该行**写回主存对应块，以进行主存更新**。各种可行的写策略都对性能和价格进行了权衡，

#### (1) 写直达(write through)

写操作直接对内存和cache进行，保证主存与cache数据的一致性。

**缺点**：产生了大量的存储通信量，可能引起瓶颈

#### (2) 回写(write back)

写回法( Write-back) ,又称为拷回法( Copy back) ,即**写操作时只把数据写人Cache 而不写人主存**,但当Cache数据**被替换出去**时才写回主存。可见写回法Cache中的数据会与主存中的不一致。为了识别Cache中的数据是否与主存一致,Cache 中的每一块要增设一个标志位,该位有两个状态:“清"(表示未修改过,与主存一致)和“脏”(表示修改过,与主存不一致)。在Cache替换时,“清"的Cache块不必写回主存,因为此时主存中相应块的内容与Cache块是一致的。在写Cache时,要将该标志位设置为“浊”,替换时此Cache块要写回主存，同时要使标志位为“清”。

适用于迭次操作和 I/O 模块直接连接到cache的系统 

**缺点**：

> 内存中的某些内容无效 
>
> 电路很复杂 
>
> cache可能成为瓶颈

**比较**：写直达法的写操作时间就是访问主存的时间；写回法写操作时间是访问cache的时间，对主存的写操作只发生在块替换时。

**举例**：

> 考虑一个行大小为 32字节的cache和一个传送一个4字节字用时30ns的主存。cache的任意行被替换之前至少已被写过一次，如果要使写回法比写直达法更高效，在被替换之前平均每行被写的次数是多少?
>
> 采用写回法时，每一个脏行只在交换时写回主存一次，需要8 x 30 =240ns。而采用写直达法时，每一次更新cache中的某行都要求有一个字写到主存，耗时30ns。因此，如果行换出之前写人平均超过8次的话，则写回法更有效。
> 

#### (3) 多机系统

保证cache一致性的策略如下：

> 写直达的总线检测
>
> 硬件透明：如果某一个cpu修改了自己cache中的字，则同时会修改主存对应单元，任何其他cache中相同的字也会修改
>
> 非cache存储器

### 4.3.6 行大小

**局部性原理**：被访问字附近的数据很可能会在不久的将来被访问

### 4.3.7 cache数量

#### (1) 单cache与多级cache

芯片内cache(on-chip cache)与芯片外cache(off-chip cache)：芯片内的cache大小会被限制

使用多级cache：两级cache：片内cache为第一级L1，外部cache为第二级L2

> 片上缓存L1 (On-chip Cache):到CPU的路径短，速度快，降低总线访问频率
>
> 片外缓存L2 (Off-chip Cache):只有L1访问缺失才会导致访问L2

#### (2) unified cache与split cache

统一缓存是指指令和数据都存放在同--缓存内的Cache;分立缓存是指指令和数据分别存放在两个缓存中,一个称为指令Cache,一个称为数据Cache。

分立cache适用于分布式操作，当采用**超前控制或流水线控制方式**时,一般都采用分立缓存；，统一cache命中率高

两种缓存的选用主要考虑如下两个因素

> 其一,它与主存结构有关,如果计算机的主存是统一的(指令、数据存储在同一主存内),则相应的Cache采用统一缓存;如果主存采用指令、数据分开存储的方案,则相应的Cache采用分立缓存。
>
> 其二,它与机器对指令执行的控制方式有关。当采用**超前控制或流水线控制方式**时,一般都采用分立缓存。
>

